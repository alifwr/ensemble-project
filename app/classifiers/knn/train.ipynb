{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a84a145",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Training\n",
    "## Network Intrusion Detection using UNSW-NB15 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfffc4d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Ensure the UNSW-NB15 dataset files are placed in the `data/` directory:\n",
    "  - `UNSW_NB15_training-set.csv`\n",
    "  - `UNSW_NB15_testing-set.csv`\n",
    "- Install dependencies: `uv sync`\n",
    "- Run this notebook from the project root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ddea4",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e5bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "import time\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from app.utils.preprocessor import UNSWNB15Preprocessor\n",
    "from app.classifiers.knn.model import KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8af93",
   "metadata": {},
   "source": [
    "## 2. Initialize Model and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e5f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = UNSWNB15Preprocessor()\n",
    "# Use batch_size=1000 to prevent memory overflow on large datasets\n",
    "model = KNN(n_neighbors=5, weights='uniform', metric='euclidean', batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942abf9",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5abcb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from: c:\\Users\\ACER\\OneDrive\\Documents\\Kerja\\self\\ensemble-project\\data\\UNSW_NB15_training-set.csv\n",
      "Loading testing data from: c:\\Users\\ACER\\OneDrive\\Documents\\Kerja\\self\\ensemble-project\\data\\UNSW_NB15_testing-set.csv\n",
      "Training samples: 82332\n",
      "Testing samples: 175341\n",
      "Features: 42\n",
      "Classes: 2\n",
      "Training samples: 82332\n",
      "Testing samples: 175341\n",
      "Features: 42\n",
      "Classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Define paths to data files\n",
    "data_dir = project_root / 'data'\n",
    "train_path = data_dir / 'UNSW_NB15_training-set.csv'\n",
    "test_path = data_dir / 'UNSW_NB15_testing-set.csv'\n",
    "\n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = preprocessor.load_data(\n",
    "    train_path=str(train_path),\n",
    "    test_path=str(test_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105952be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files found:\n",
      "Training: c:\\Users\\ACER\\OneDrive\\Documents\\Kerja\\self\\ensemble-project\\data\\UNSW_NB15_training-set.csv\n",
      "Testing: c:\\Users\\ACER\\OneDrive\\Documents\\Kerja\\self\\ensemble-project\\data\\UNSW_NB15_testing-set.csv\n"
     ]
    }
   ],
   "source": [
    "# Check if data files exist\n",
    "if not train_path.exists():\n",
    "    raise FileNotFoundError(f\"Training data file not found: {train_path}\")\n",
    "if not test_path.exists():\n",
    "    raise FileNotFoundError(f\"Testing data file not found: {test_path}\")\n",
    "\n",
    "print(f\"Data files found:\")\n",
    "print(f\"Training: {train_path}\")\n",
    "print(f\"Testing: {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf70dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preprocessing Training Data ===\n",
      "Handling missing values...\n",
      "Encoding categorical features...\n",
      "Creating engineered features...\n",
      "Scaling features...\n",
      "Encoding labels...\n",
      "Final feature dimension: 52\n",
      "Preprocessing complete!\n",
      "\n",
      "=== Preprocessing Test Data ===\n",
      "Test samples processed: 175341\n",
      "Preprocessing complete!\n",
      "Test samples processed: 175341\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "X_train_processed, y_train_encoded = preprocessor.fit_transform(X_train, y_train)\n",
    "X_test_processed, y_test_encoded = preprocessor.transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b190a3",
   "metadata": {},
   "source": [
    "## 4. Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc5dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET INFORMATION\n",
      "============================================================\n",
      "Input dimension: 52\n",
      "Number of classes: 2\n",
      "Training samples: 82332\n",
      "Testing samples: 175341\n",
      "Classes: ['0', '1']\n"
     ]
    }
   ],
   "source": [
    "classes = preprocessor.get_class_names()\n",
    "class_names = [str(c) for c in classes]\n",
    "features = preprocessor.get_feature_names()\n",
    "\n",
    "input_dim = X_train_processed.shape[1]\n",
    "num_classes = len(classes)\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'DATASET INFORMATION')\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'Input dimension: {input_dim}')\n",
    "print(f'Number of classes: {num_classes}')\n",
    "print(f'Training samples: {X_train_processed.shape[0]}')\n",
    "print(f'Testing samples: {X_test_processed.shape[0]}')\n",
    "print(f'Classes: {class_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1608f",
   "metadata": {},
   "source": [
    "## 5. Train KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d14244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING KNN MODEL\n",
      "============================================================\n",
      "Number of neighbors: 5\n",
      "Weights: uniform\n",
      "Distance metric: euclidean\n",
      "Batch size: 1000\n",
      "\n",
      "Training started...\n",
      "Training completed in 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'TRAINING KNN MODEL')\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'Number of neighbors: {model.n_neighbors}')\n",
    "print(f'Weights: {model.weights}')\n",
    "print(f'Distance metric: {model.metric}')\n",
    "print(f'Batch size: {model.batch_size}')\n",
    "print(f'\\nTraining started...')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_processed, y_train_encoded)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d8521",
   "metadata": {},
   "source": [
    "## 6. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af7ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions on training set...\n",
      "Making predictions on test set (batch processing)...\n",
      "Making predictions on test set (batch processing)...\n",
      "Predictions complete!\n",
      "Predictions complete!\n"
     ]
    }
   ],
   "source": [
    "# Make predictions (processing in batches to avoid memory issues)\n",
    "print(f'\\nMaking predictions on training set...')\n",
    "y_train_pred = model.predict(X_train_processed)\n",
    "\n",
    "if y_test_encoded is not None:\n",
    "    print(f'Making predictions on test set (batch processing)...')\n",
    "    y_test_pred = model.predict(X_test_processed)\n",
    "    print(f'Predictions complete!')\n",
    "else:\n",
    "    raise ValueError(\"y_test_encoded is None - labels are required for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620b987",
   "metadata": {},
   "source": [
    "## 7. Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1dc8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "\n",
    "train_precision = precision_score(y_train_encoded, y_train_pred, average='weighted', zero_division=0)\n",
    "test_precision = precision_score(y_test_encoded, y_test_pred, average='weighted', zero_division=0)\n",
    "\n",
    "train_recall = recall_score(y_train_encoded, y_train_pred, average='weighted', zero_division=0)\n",
    "test_recall = recall_score(y_test_encoded, y_test_pred, average='weighted', zero_division=0)\n",
    "\n",
    "train_f1 = f1_score(y_train_encoded, y_train_pred, average='weighted', zero_division=0)\n",
    "test_f1 = f1_score(y_test_encoded, y_test_pred, average='weighted', zero_division=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1481b2c",
   "metadata": {},
   "source": [
    "## 8. Display Overall Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce06e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION\n",
      "============================================================\n",
      "\n",
      "Overall Performance Metrics:\n",
      "------------------------------------------------------------\n",
      "Metric               Training             Testing             \n",
      "------------------------------------------------------------\n",
      "Accuracy             0.9558               0.8671              \n",
      "Precision            0.9568               0.8952              \n",
      "Recall               0.9558               0.8671              \n",
      "F1-Score             0.9559               0.8710              \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'MODEL EVALUATION')\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'\\nOverall Performance Metrics:')\n",
    "print(f'{\"-\"*60}')\n",
    "print(f'{\"Metric\":<20} {\"Training\":<20} {\"Testing\":<20}')\n",
    "print(f'{\"-\"*60}')\n",
    "print(f'{\"Accuracy\":<20} {train_accuracy:<20.4f} {test_accuracy:<20.4f}')\n",
    "print(f'{\"Precision\":<20} {train_precision:<20.4f} {test_precision:<20.4f}')\n",
    "print(f'{\"Recall\":<20} {train_recall:<20.4f} {test_recall:<20.4f}')\n",
    "print(f'{\"F1-Score\":<20} {train_f1:<20.4f} {test_f1:<20.4f}')\n",
    "print(f'{\"-\"*60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b5b90",
   "metadata": {},
   "source": [
    "## 9. Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e9f001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETAILED CLASSIFICATION REPORT (Test Set)\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82     56000\n",
      "           1       0.98      0.82      0.89    119341\n",
      "\n",
      "    accuracy                           0.87    175341\n",
      "   macro avg       0.85      0.89      0.86    175341\n",
      "weighted avg       0.90      0.87      0.87    175341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'DETAILED CLASSIFICATION REPORT (Test Set)')\n",
    "print(f'{\"=\"*60}')\n",
    "print(classification_report(y_test_encoded, y_test_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c955226",
   "metadata": {},
   "source": [
    "## 10. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6a8bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONFUSION MATRIX (Test Set)\n",
      "============================================================\n",
      "\n",
      "Rows: True labels, Columns: Predicted labels\n",
      "Classes: ['0', '1']\n",
      "\n",
      "[[53820  2180]\n",
      " [21123 98218]]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'CONFUSION MATRIX (Test Set)')\n",
    "print(f'{\"=\"*60}')\n",
    "cm = confusion_matrix(y_test_encoded, y_test_pred)\n",
    "print(f'\\nRows: True labels, Columns: Predicted labels')\n",
    "print(f'Classes: {class_names}\\n')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c9f394",
   "metadata": {},
   "source": [
    "## 11. Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeff6611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PER-CLASS ACCURACY (Test Set)\n",
      "============================================================\n",
      "0                   : 0.9611 (56000 samples)\n",
      "1                   : 0.8230 (119341 samples)\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'PER-CLASS ACCURACY (Test Set)')\n",
    "print(f'{\"=\"*60}')\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = (y_test_encoded == i)\n",
    "    num_samples = int(np.sum(class_mask))\n",
    "    if num_samples > 0:\n",
    "        class_accuracy = float(np.sum(y_test_pred[class_mask] == i)) / num_samples\n",
    "        print(f'{class_name:<20}: {class_accuracy:.4f} ({num_samples} samples)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632abf3",
   "metadata": {},
   "source": [
    "## 12. Save Report to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c4494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING REPORT\n",
      "============================================================\n",
      "\n",
      "Report saved to: c:\\Users\\ACER\\OneDrive\\Documents\\Kerja\\self\\ensemble-project\\results\\knn_classification_report.txt\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'SAVING REPORT')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "report_dir = project_root / 'results'\n",
    "report_dir.mkdir(exist_ok=True)\n",
    "report_file = report_dir / 'knn_classification_report.txt'\n",
    "\n",
    "# Calculate confusion matrix for the report\n",
    "cm = confusion_matrix(y_test_encoded, y_test_pred)\n",
    "\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'KNN CLASSIFICATION REPORT\\n')\n",
    "    f.write(f'{\"=\"*60}\\n\\n')\n",
    "    \n",
    "    f.write(f'Training Date: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "    f.write(f'Training Time: {training_time:.2f} seconds\\n\\n')\n",
    "    \n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'MODEL CONFIGURATION\\n')\n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'Number of neighbors: {model.n_neighbors}\\n')\n",
    "    f.write(f'Weights: {model.weights}\\n')\n",
    "    f.write(f'Distance metric: {model.metric}\\n')\n",
    "    f.write(f'Batch size: {model.batch_size}\\n\\n')\n",
    "    \n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'DATASET INFORMATION\\n')\n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'Input dimension: {input_dim}\\n')\n",
    "    f.write(f'Number of classes: {num_classes}\\n')\n",
    "    f.write(f'Training samples: {X_train_processed.shape[0]}\\n')\n",
    "    f.write(f'Testing samples: {X_test_processed.shape[0]}\\n')\n",
    "    f.write(f'Classes: {\", \".join(class_names)}\\n\\n')\n",
    "    \n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'OVERALL PERFORMANCE METRICS\\n')\n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'{\"Metric\":<20} {\"Training\":<20} {\"Testing\":<20}\\n')\n",
    "    f.write(f'{\"-\"*60}\\n')\n",
    "    f.write(f'{\"Accuracy\":<20} {train_accuracy:<20.4f} {test_accuracy:<20.4f}\\n')\n",
    "    f.write(f'{\"Precision\":<20} {train_precision:<20.4f} {test_precision:<20.4f}\\n')\n",
    "    f.write(f'{\"Recall\":<20} {train_recall:<20.4f} {test_recall:<20.4f}\\n')\n",
    "    f.write(f'{\"F1-Score\":<20} {train_f1:<20.4f} {test_f1:<20.4f}\\n')\n",
    "    f.write(f'{\"-\"*60}\\n\\n')\n",
    "    \n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'DETAILED CLASSIFICATION REPORT (Test Set)\\n')\n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    report_str = classification_report(y_test_encoded, y_test_pred, target_names=class_names)\n",
    "    f.write(str(report_str))\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'CONFUSION MATRIX (Test Set)\\n')\n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'Rows: True labels, Columns: Predicted labels\\n')\n",
    "    f.write(f'Classes: {\", \".join(class_names)}\\n\\n')\n",
    "    f.write(str(cm))\n",
    "    f.write('\\n\\n')\n",
    "    \n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    f.write(f'PER-CLASS ACCURACY (Test Set)\\n')\n",
    "    f.write(f'{\"=\"*60}\\n')\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_mask = (y_test_encoded == i)\n",
    "        num_samples = int(np.sum(class_mask))\n",
    "        if num_samples > 0:\n",
    "            class_accuracy = float(np.sum(y_test_pred[class_mask] == i)) / num_samples\n",
    "            f.write(f'{class_name:<20}: {class_accuracy:.4f} ({num_samples} samples)\\n')\n",
    "\n",
    "print(f'\\nReport saved to: {report_file}')\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'TRAINING COMPLETE')\n",
    "print(f'{\"=\"*60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc292756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
